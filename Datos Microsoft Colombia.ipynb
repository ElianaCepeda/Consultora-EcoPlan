{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ddf6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librerías importadas correctamente.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from shapely.geometry import shape  # Para convertir el JSON de geometría a un objeto\n",
    "import itertools                   # Para leer el archivo por partes\n",
    "\n",
    "\n",
    "\n",
    "print(\"Librerías importadas correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcdbdc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectado a BD compañera (Lectura): 'is394508_db'\n",
      "Conectado a BD propia (Escritura): 'is394512_db'\n",
      "¡Ambas conexiones a MongoDB exitosas!\n"
     ]
    }
   ],
   "source": [
    "# --- Configuración del Proceso ---\n",
    "\n",
    "# Cambia esto a False para procesar el archivo completo con chunks de 500\n",
    "PROBAR_CON_100_DATOS = True\n",
    "TAMANO_CHUNK = 500 # Relevante solo si PROBAR_CON_100_DATOS = False\n",
    "\n",
    "# --- Conexión al MongoDB externo (SOLO LECTURA) ---\n",
    "# Molde de la Entrega 2\n",
    "CADENA_CONEXION_COMPANERA = \"mongodb://is394508:Y7hXfRv10UmhRPH@orion.javeriana.edu.co:27017/is394508_db?authSource=is394508_db\"\n",
    "NOMBRE_BASE_DATOS_COMPANERA = \"is394508_db\"\n",
    "COLECCION_MUNICIPIOS_COMPANERA = \"municipios\"\n",
    "\n",
    "# --- Conexión a local MongoDB (ESCRITURA) ---\n",
    "# Usamos esto para escribir los edificios filtrados\n",
    "CADENA_CONEXION_PROPIA = \"mongodb://is394512:TsqJFgPGAnbMH8f@orion.javeriana.edu.co:27017/is394512_db?authSource=is394512_db\"\n",
    "NOMBRE_BASE_DATOS_PROPIA = \"is394512_db\"\n",
    "COLECCION_EDIFICIOS_PROPIA = \"edificios_microsoft_pdet\" # Nueva colección limpia\n",
    "\n",
    "# --- Conexiones a MongoDB ---\n",
    "try:\n",
    "    # Cliente para leer municipios PDET\n",
    "    client_lectura = MongoClient(CADENA_CONEXION_COMPANERA)\n",
    "    db_lectura = client_lectura[NOMBRE_BASE_DATOS_COMPANERA]\n",
    "    collection_municipios = db_lectura[COLECCION_MUNICIPIOS_COMPANERA]\n",
    "    print(f\"Conectado a BD (Lectura): '{NOMBRE_BASE_DATOS_COMPANERA}'\")\n",
    "    \n",
    "    # Cliente para escribir tus edificios\n",
    "    client_escritura = MongoClient(CADENA_CONEXION_PROPIA)\n",
    "    db_escritura = client_escritura[NOMBRE_BASE_DATOS_PROPIA]\n",
    "    collection_edificios = db_escritura[COLECCION_EDIFICIOS_PROPIA]\n",
    "    print(f\"Conectado a BD (Escritura): '{NOMBRE_BASE_DATOS_PROPIA}'\")\n",
    "\n",
    "    # Validar ambas conexiones\n",
    "    client_lectura.admin.command('ping')\n",
    "    client_escritura.admin.command('ping')\n",
    "    print(\"¡Ambas conexiones a MongoDB exitosas!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error conectando a MongoDB: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e132653e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando la carga de municipios PDET desde MongoDB (Compañera)...\n",
      "Unificando todas las geometrías PDET en una sola (unary_union)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Simon Esteban G\\AppData\\Local\\Temp\\ipykernel_8088\\2815845256.py:32: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  filtro_pdet_unificado = gdf_municipios_pdet.geometry.unary_union\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Filtro PDET listo! (170 municipios cargados en 13.94s)\n",
      "Conexión de Lectura (Compañera) cerrada.\n"
     ]
    }
   ],
   "source": [
    "print(\"Iniciando la carga de municipios PDET desde MongoDB (Compañera)...\")\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # Trae todos los documentos de la colección 'municipios'\n",
    "    cursor_municipios = collection_municipios.find({})\n",
    "    lista_municipios_docs = list(cursor_municipios)\n",
    "    \n",
    "    if not lista_municipios_docs:\n",
    "        print(\"¡ERROR! La colección 'municipios' está vacía. No se puede filtrar.\")\n",
    "        raise ValueError(\"No se encontraron municipios PDET.\")\n",
    "\n",
    "    # 1. Cargamos los documentos en un DataFrame de PANDAS\n",
    "    df_municipios = pd.DataFrame(lista_municipios_docs)\n",
    "\n",
    "    # 2. Convertimos la columna 'geometria' (que son dicts)\n",
    "    #    a objetos de geometría de Shapely\n",
    "    geometrias_shapely = df_municipios['geometria'].apply(shape)\n",
    "\n",
    "    # 3. Creamos el GeoDataFrame\n",
    "    gdf_municipios_pdet = gpd.GeoDataFrame(\n",
    "        df_municipios, \n",
    "        geometry=geometrias_shapely, \n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "    \n",
    "    # 4. Optimizamos el filtro: Unimos todos los 170 polígonos en UNO SOLO\n",
    "    print(\"Unificando todas las geometrías PDET en una sola (unary_union)...\")\n",
    "    filtro_pdet_unificado = gdf_municipios_pdet.geometry.unary_union\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"¡Filtro PDET listo! ({len(lista_municipios_docs)} municipios cargados en {end_time - start_time:.2f}s)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error cargando los municipios desde MongoDB: {e}\")\n",
    "    raise\n",
    "finally:\n",
    "    # Cerramos la conexión de lectura, ya no la necesitamos\n",
    "    client_lectura.close()\n",
    "    print(\"Conexión de Lectura (Compañera) cerrada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0e12e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparando tu colección de destino 'edificios_microsoft_pdet'...\n",
      "Limpiando colección 'edificios_microsoft_pdet' (método: drop)...\n",
      "Colección antigua eliminada.\n",
      "Creando índice espacial '2dsphere' (sparse=True)...\n",
      "¡Índice 2dsphere creado en 0.03s!\n"
     ]
    }
   ],
   "source": [
    "print(f\"Preparando tu colección de destino '{COLECCION_EDIFICIOS_PROPIA}'...\")\n",
    "\n",
    "try:\n",
    "    # 1. Limpiamos la colección para empezar de cero\n",
    "    print(f\"Limpiando colección '{COLECCION_EDIFICIOS_PROPIA}' (método: drop)...\")\n",
    "    collection_edificios.drop()\n",
    "    print(\"Colección antigua eliminada.\")\n",
    "\n",
    "    # 2. Crear el índice espacial 2dsphere\n",
    "    # Lo creamos ANTES de insertar. Usamos sparse=True\n",
    "    # para ignorar geometrías inválidas de Microsoft.\n",
    "    print(\"Creando índice espacial '2dsphere' (sparse=True)...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    collection_edificios.create_index(\n",
    "        [(\"geometria\", pymongo.GEOSPHERE)], \n",
    "        sparse=True\n",
    "    )\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"¡Índice 2dsphere creado en {end_time - start_time:.2f}s!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error preparando la colección de destino: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5c62fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo de entrada (Microsoft): C:\\Users\\Simon Esteban G\\Downloads\\Colombia.geojsonl\n"
     ]
    }
   ],
   "source": [
    "# --- Configuración de Archivos Locales ---\n",
    "RUTA_GEOJSONL_MICROSOFT = r\"C:\\Users\\Simon Esteban G\\Downloads\\Colombia.geojsonl\"\n",
    "\n",
    "print(f\"Archivo de entrada (Microsoft): {RUTA_GEOJSONL_MICROSOFT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168f6efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando el proceso ETL para: C:\\Users\\Simon Esteban G\\Downloads\\Colombia.geojsonl\n",
      "MODO PRUEBA: Leyendo primeras 100 líneas...\n",
      "MODO PRUEBA: Proceso de 100 líneas completado.\n",
      "Conexión de Escritura (Propia) cerrada.\n",
      "\n",
      "--- ¡PROCESO COMPLETO! ---\n",
      "Tiempo total: 0.00 minutos\n",
      "Total de líneas (edificios) procesadas del archivo: 100\n",
      "Total de edificios PDET cargados en tu BD: 61\n"
     ]
    }
   ],
   "source": [
    "# Este bloque reemplaza el pd.read_csv y lee tu GeoJSONL\n",
    "\n",
    "print(f\"Iniciando el proceso ETL para: {RUTA_GEOJSONL_MICROSOFT}\")\n",
    "\n",
    "# Contadores para el reporte final\n",
    "total_lineas_procesadas = 0\n",
    "total_edificios_cargados = 0\n",
    "start_time_proceso = time.time()\n",
    "\n",
    "# Abrimos el archivo GeoJSONL\n",
    "try:\n",
    "    with open(RUTA_GEOJSONL_MICROSOFT, 'r', encoding='utf-8') as f:\n",
    "        \n",
    "        # Bucle principal: Leer el archivo en chunks\n",
    "        while True:\n",
    "            # Selecciona la cantidad de líneas a leer\n",
    "            if PROBAR_CON_100_DATOS:\n",
    "                print(f\"MODO PRUEBA: Leyendo primeras 100 líneas...\")\n",
    "                lineas_chunk_str = list(itertools.islice(f, 100))\n",
    "            else:\n",
    "                lineas_chunk_str = list(itertools.islice(f, TAMANO_CHUNK))\n",
    "\n",
    "            # Si no hay más líneas, salimos del bucle\n",
    "            if not lineas_chunk_str:\n",
    "                break \n",
    "\n",
    "            total_lineas_procesadas += len(lineas_chunk_str)\n",
    "            geometrias_json_validas = []\n",
    "\n",
    "            # 1. (T) Transformar: Convertir líneas de string a JSON (dict)\n",
    "            for linea in lineas_chunk_str:\n",
    "                try:\n",
    "                    geom_json = json.loads(linea)\n",
    "                    # Validamos que sea una geometría (como descubrimos antes)\n",
    "                    if 'type' in geom_json and 'coordinates' in geom_json:\n",
    "                        geometrias_json_validas.append(geom_json)\n",
    "                except json.JSONDecodeError:\n",
    "                    continue # Ignora líneas mal formadas\n",
    "\n",
    "            if not geometrias_json_validas:\n",
    "                continue # Pasa al siguiente chunk si este estaba vacío\n",
    "\n",
    "            # 2. (T) Transformar: Convertir dicts a Geometrías Shapely\n",
    "            geometrias_shapely = [shape(g) for g in geometrias_json_validas]\n",
    "\n",
    "            # 3. (T) Transformar: Crear el GeoDataFrame del chunk\n",
    "            gdf_chunk = gpd.GeoDataFrame(\n",
    "                geometry=geometrias_shapely, \n",
    "                crs=\"EPSG:4326\"\n",
    "            )\n",
    "\n",
    "            # 4. (T) Filtrar: Usamos el filtro unificado (EL \"MOLDE\")\n",
    "            gdf_filtrado = gdf_chunk[gdf_chunk.geometry.intersects(filtro_pdet_unificado)]\n",
    "\n",
    "            # 5. (L) Cargar: Si encontramos edificios, los procesamos\n",
    "            if not gdf_filtrado.empty:\n",
    "                \n",
    "                # 6. (T) Calcular Área \n",
    "                # Proyectamos a un CRS de Colombia (MAGNA-SIRGAS 3116)\n",
    "                gdf_proyectado = gdf_filtrado.to_crs(\"EPSG:3116\")\n",
    "                areas_m2 = gdf_proyectado.geometry.area\n",
    "                \n",
    "                # Volvemos a WGS84 (4326) para MongoDB\n",
    "                gdf_listo_para_mongo = gdf_proyectado.to_crs(\"EPSG:4326\")\n",
    "                \n",
    "                # Añadimos la columna de área\n",
    "                gdf_listo_para_mongo['area_m2'] = areas_m2\n",
    "                \n",
    "                # 7. (L) Formatear y Cargar\n",
    "                documentos_para_insertar = []\n",
    "                for _, edificio in gdf_listo_para_mongo.iterrows():\n",
    "                    documento_json = {\n",
    "                        \"fuente\": \"microsoft\",\n",
    "                        \"area_m2\": edificio['area_m2'],\n",
    "                        \"geometria\": edificio['geometry'].__geo_interface__\n",
    "                    }\n",
    "                    documentos_para_insertar.append(documento_json)\n",
    "                \n",
    "                # Insertar el lote de documentos en TU base de datos\n",
    "                collection_edificios.insert_many(documentos_para_insertar)\n",
    "                \n",
    "                total_edificios_cargados += len(documentos_para_insertar)\n",
    "            \n",
    "            # Si estamos en modo prueba, salimos después del primer lote\n",
    "            if PROBAR_CON_100_DATOS:\n",
    "                print(\"MODO PRUEBA: Proceso de 100 líneas completado.\")\n",
    "                break # Salimos del 'while True'\n",
    "\n",
    "            # Reporte de progreso\n",
    "            print(f\"Chunk procesado. Líneas leídas: {total_lineas_procesadas}, Edificios PDET cargados: {total_edificios_cargados}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"¡ERROR! No se encontró el archivo en: {RUTA_GEOJSONL_MICROSOFT}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error inesperado durante el ETL: {e}\")\n",
    "finally:\n",
    "    # Cerramos la conexión de escritura\n",
    "    client_escritura.close()\n",
    "    print(\"Conexión de Escritura (Propia) cerrada.\")\n",
    "\n",
    "end_time_proceso = time.time()\n",
    "print(\"\\n--- ¡PROCESO COMPLETO! ---\")\n",
    "print(f\"Tiempo total: {(end_time_proceso - start_time_proceso) / 60:.2f} minutos\")\n",
    "print(f\"Total de líneas (edificios) procesadas del archivo: {total_lineas_procesadas}\")\n",
    "print(f\"Total de edificios PDET cargados en tu BD: {total_edificios_cargados}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
